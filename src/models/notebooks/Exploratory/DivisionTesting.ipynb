{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to C:\\Users\\Alex\\OneDrive\\Documents\\GitHub\\UFC_Prediction_2022\\src\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# standard library imports\n",
    "import git, os, sys\n",
    "\n",
    "git_repo = git.Repo(os.getcwd(), search_parent_directories=True)\n",
    "git_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "os.chdir(f'{git_root}/src')\n",
    "sys.path.append(os.path.abspath(os.path.join(f'{git_root}/src')))\n",
    "print(f'Changed working directory to {os.getcwd()}')\n",
    "\n",
    "# local imports\n",
    "from fight_stat_helpers import *\n",
    "from data_handler import DataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = DataHandler()\n",
    "# get reported derived doubled data\n",
    "ufc_fights_reported_derived_doubled = dh.get('ufc_fights_reported_derived_doubled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9862, 326)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take fights in the last 10 years\n",
    "ufc_fights_reported_derived_doubled['date'] = pd.to_datetime(ufc_fights_reported_derived_doubled['date'])\n",
    "date_10_years_ago = pd.Timestamp.now() - pd.DateOffset(years=10)\n",
    "ufc_fights_reported_derived_doubled = ufc_fights_reported_derived_doubled[ufc_fights_reported_derived_doubled['date'] >= date_10_years_ago]\n",
    "ufc_fights_reported_derived_doubled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_fights_predictive_flattened_diffs = dh.make_ufc_fights_predictive_flattened_diffs(ufc_fights_reported_derived_doubled)\n",
    "ufc_fights_predictive_flattened_diffs = dh.clean_ufc_fights_for_winner_prediction(ufc_fights_predictive_flattened_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# got 64 % on a test set\n",
    "amazing_feature_set =  [\n",
    "'age_diff',\n",
    "'reach_diff',\n",
    "'l5y_wins_diff',\n",
    "'l5y_losses_ko_diff',\n",
    "'all_wins_wins_diff',\n",
    "'l5y_wins_wins_diff',\n",
    "'l5y_losses_losses_diff',\n",
    "'all_losses_losses_diff',\n",
    "'l3y_losses_sub_diff',\n",
    "'l1y_wins_sub_diff',\n",
    "'l1y_wins_diff',\n",
    "# 'all_wins_diff',\n",
    "'l3y_fight_math_diff',\n",
    "'all_inf_control_per_min_diff',\n",
    "'all_inf_distance_strikes_accuracy_diff',\n",
    "'l1y_inf_takedowns_landed_per_min_diff',\n",
    "# 'l1y_inf_takedowns_attempts_per_min_diff',\n",
    "'l3y_inf_takedowns_attempts_per_min_diff',\n",
    "'l3y_inf_ground_strikes_attempts_per_min_diff',\n",
    "'all_inf_body_strikes_accuracy_diff',\n",
    "'l1y_inf_body_strikes_attempts_per_min_diff',\n",
    "'l5y_inf_body_strikes_attempts_per_min_diff',\n",
    "'all_inf_clinch_strikes_landed_per_min_diff',\n",
    "# 'l5y_inf_clinch_strikes_attempts_per_min_diff',\n",
    "'l1y_inf_total_strikes_landed_per_min_diff',\n",
    "'l1y_abs_knockdowns_per_min_diff',\n",
    "'l1y_abs_takedowns_attempts_per_min_diff',\n",
    "'all_abs_takedowns_attempts_per_min_diff',\n",
    "'l3y_abs_head_strikes_accuracy_diff',\n",
    "'l1y_abs_body_strikes_accuracy_diff',\n",
    "'l3y_abs_body_strikes_accuracy_diff',\n",
    "# 'l1y_abs_clinch_strikes_accuracy_diff',\n",
    "'l3y_abs_clinch_strikes_landed_per_min_diff',\n",
    "'l3y_abs_clinch_strikes_accuracy_diff',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the 'fighter_result' column and opponent_result column as it is not needed for the model and also fighter and opponent columns\n",
    "X = ufc_fights_predictive_flattened_diffs\n",
    "# KEEP result in X as this is what model_score is expecting for better or for worse\n",
    "y = X['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the entire data set with all features as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (3381, 325) accuracy: 0.6418219461697723\n",
      "Test set size: (846, 325) accuracy: 0.6536643026004728\n",
      "Test set neg log loss: -0.6360888359968085. Average probability to observe data given model: 0.5293587895040919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6418219461697723, 0.6536643026004728)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test_score(X_train, X_test, amazing_feature_set, _max_iter = 20000, scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lightweight', \"Women's Bantamweight\", 'Bantamweight',\n",
       "       'Heavyweight', 'Featherweight', 'Middleweight',\n",
       "       'Light Heavyweight', \"Women's Flyweight\", \"Women's Strawweight\",\n",
       "       'Welterweight', 'Flyweight', 'Catch Weight',\n",
       "       \"Women's Featherweight\"], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['division'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 320)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the part of X_test that is in division middleweight, light heavyweight, heavyweight\n",
    "heavy_division_list = ['Middleweight', 'Light Heavyweight', 'Heavyweight']\n",
    "light_division_list = ['Lightweight', 'Featherweight', 'Bantamweight', 'Flyweight', 'Welterweight']\n",
    "women_division_list = ['Women\\'s Bantamweight', 'Women\\'s Featherweight', 'Women\\'s Flyweight', 'Women\\'s Strawweight']\n",
    "all_division_list = heavy_division_list + light_division_list + women_division_list\n",
    "division_list = women_division_list\n",
    "X_test_division = X_test[X_test['division'].isin(division_list)]\n",
    "y_test_division = y_test[X_test['division'].isin(division_list)]\n",
    "X_test_division = X_test_division.drop(columns=['result', 'fighter', 'opponent', 'method','division'])\n",
    "X_test_division.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (3381, 30) accuracy: 0.640047323277137\n",
      "Test set size: (117, 320) accuracy: 0.6410256410256411\n",
      "Test set neg log loss: -0.6303558587867399. Average probability to observe data given model: 0.5324023072532715\n"
     ]
    }
   ],
   "source": [
    "# fit model on training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "best_model = LogisticRegression(solver='lbfgs', max_iter=20000, C=0.1, penalty='l2', fit_intercept=False)\n",
    "scaler = StandardScaler()\n",
    "X_train_cleaned = X_train[amazing_feature_set]\n",
    "X_train_scaled = scaler.fit_transform(X_train_cleaned)\n",
    "X_test_scaled = scaler.transform(X_test_division[amazing_feature_set])\n",
    "\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# evaluate the model on the training set\n",
    "train_score = best_model.score(X_train_scaled, y_train)\n",
    "print(f'Training set size: {X_train_cleaned.shape} accuracy: {train_score}')\n",
    "\n",
    "# evaluate the model on the test set\n",
    "test_score = best_model.score(X_test_scaled, y_test_division)\n",
    "print(f'Test set size: {X_test_division.shape} accuracy: {test_score}')\n",
    "\n",
    "# get the neg log loss score of the test set and convert it to a probability\n",
    "y_proba_test = best_model.predict_proba(X_test_scaled)\n",
    "log_loss = sklearn.metrics.log_loss(y_test_division, y_proba_test)\n",
    "print(f'Test set neg log loss: {-log_loss}. Average probability to observe data given model: {np.exp(-log_loss)}')\n",
    "\n",
    "theta = list(best_model.coef_[0])\n",
    "b = best_model.intercept_[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
